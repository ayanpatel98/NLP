{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8a0abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64318c2c",
   "metadata": {},
   "source": [
    "Task 1: Vocabulary Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9af09273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the selected threshold for unknown words replacement? 2\n",
      "What is the total size of your vocabulary 23183\n",
      "What is the total occurrences of the special token '<unk>' after replacement? 20011\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train', sep='\\t', names=['idx', 'name', 'tag'])\n",
    "df['frequency'] = df['name'].map(df['name'].value_counts())\n",
    "def replace_unk(entry):\n",
    "    if entry['frequency']<=1:\n",
    "        return '<unk>'\n",
    "    else:\n",
    "        return entry['name']\n",
    "\n",
    "df['name'] = df.apply(lambda entry: replace_unk(entry), axis=1)\n",
    "\n",
    "# Sort by descending freq\n",
    "df = df.sort_values(by=['frequency'], ascending=False)\n",
    "# Return a Series containing counts of unique values.\n",
    "df_counted = df['name'].value_counts().reset_index()\n",
    "df_counted.columns = [''] * len(df_counted.columns)\n",
    "\n",
    "df_counted.columns = ['name', 'frequency']\n",
    "df_unknown = df_counted[df_counted['name']=='<unk>']\n",
    "\n",
    "unk_idx = df_counted[df_counted['name']=='<unk>'].index\n",
    "\n",
    "df_counted = df_counted.drop(index=unk_idx)\n",
    "df_counted = pd.concat([df_unknown, df_counted])\n",
    "df_counted = df_counted.reset_index()\n",
    "df_counted['index'] = df_counted.index+1\n",
    "columns_titles = [\"name\",\"index\", \"frequency\"]\n",
    "df_counted=df_counted.reindex(columns=columns_titles)\n",
    "df_counted.to_csv(\"vocab.txt\", sep=\"\\t\", header=None)\n",
    "\n",
    "print(\"What is the selected threshold for unknown words replacement?\", 2)\n",
    "print(\"What is the total size of your vocabulary\", len(df_counted))\n",
    "print(\"What is the total occurrences of the special token '<unk>' after replacement?\", int(df_unknown['frequency']\n",
    "                                                                                           [df_unknown['name']=='<unk>']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b9a21974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/train', sep='\\t', names=['idx', 'name', 'tag'])\n",
    "# df['frequency'] = df['name'].map(df['name'].value_counts())\n",
    "# df['name'] = df.apply(lambda entry: replace_unk(entry), axis=1)\n",
    "# df_pos = pd.DataFrame(df['tag'].value_counts()).reset_index()\n",
    "# df_pos.columns = [''] * len(df_pos.columns)\n",
    "# df_pos.columns = ['tag', 'count']\n",
    "# all_tags = list(df_pos['tag'])\n",
    "\n",
    "# all_sentences = []\n",
    "# temp_sentence = []\n",
    "# for i in range(len(df)):\n",
    "#     if df.loc[i]['idx']==1 and i!=0:\n",
    "#         all_sentences.append(temp_sentence)\n",
    "#         temp_sentence =[]\n",
    "#     temp_sentence.append((df.loc[i]['name'], df.loc[i]['tag']))\n",
    "    \n",
    "\n",
    "\n",
    "# Transition Matrix code\n",
    "transition_matrix = [[0 for j in range(len(all_tags))] for i in range(len(all_tags))]\n",
    "tag_freq = {} # format: key = <TAG>, value = <tag_freq>\n",
    "def generate_transition_matrix():\n",
    "    # Calculate tag frequency\n",
    "    for sentence in all_sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            curr_tag = sentence[i][1]\n",
    "            if curr_tag not in tag_freq:\n",
    "                tag_freq[curr_tag]=1\n",
    "            else:\n",
    "                tag_freq[curr_tag]+=1\n",
    "    \n",
    "    # 1. Calculate the number of transitions from one tag to another for each sentence\n",
    "    for sentence in all_sentences:\n",
    "        for i in range(1, len(sentence)):\n",
    "            curr_tag_index = all_tags.index(sentence[i][1])\n",
    "            prev_tag_index = all_tags.index(sentence[i-1][1])\n",
    "            transition_matrix[prev_tag_index][curr_tag_index]+=1\n",
    "    \n",
    "    # 2. Calculate the transition probabilities for each transition\n",
    "    for i in range(len(transition_matrix)):\n",
    "        for j in range(len(transition_matrix[0])):\n",
    "            prev_tag_index = i\n",
    "            prev_tag_count = tag_freq[all_tags[i]]\n",
    "            if(transition_matrix[i][j] == 0) : transition_matrix[i][j] = 1e-10\n",
    "            else: transition_matrix[i][j]/=prev_tag_count\n",
    "            \n",
    "# Emmission Matrix code\n",
    "vocabulary = list(df_counted['name'])\n",
    "emmission_matrix = [[0 for j in range(len(vocabulary))] for i in range(len(all_tags))]\n",
    "def generate_emmission_matrix():    \n",
    "    # 1. Calculate the number of transitions from one tag to another for each sentence\n",
    "    for sentence in all_sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            curr_word_index = vocabulary.index(sentence[i][0])\n",
    "            prev_tag_index = all_tags.index(sentence[i][1])\n",
    "            emmission_matrix[prev_tag_index][curr_word_index]+=1\n",
    "    \n",
    "    # 2. Calculate the transition probabilities for each transition\n",
    "    for i in range(len(emmission_matrix)):\n",
    "        for j in range(len(emmission_matrix[0])):\n",
    "            prev_tag_index = i\n",
    "            prev_tag_count = tag_freq[all_tags[i]]\n",
    "            if(emmission_matrix[i][j] == 0) : emmission_matrix[i][j] = 1e-10\n",
    "            else: emmission_matrix[i][j]/=prev_tag_count\n",
    "\n",
    "\n",
    "generate_transition_matrix()\n",
    "generate_emmission_matrix()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2fd1ed6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.49580504e-02, 1.00000000e-10, 7.84104631e-06, ...,\n",
       "        1.56820926e-05, 1.56820926e-05, 1.00000000e-10],\n",
       "       [1.68854743e-04, 1.00000000e-10, 1.00000000e-10, ...,\n",
       "        1.00000000e-10, 1.00000000e-10, 1.00000000e-10],\n",
       "       [5.51585580e-02, 1.00000000e-10, 6.84915870e-05, ...,\n",
       "        1.00000000e-10, 1.00000000e-10, 1.00000000e-10],\n",
       "       ...,\n",
       "       [1.60919540e-01, 1.00000000e-10, 1.00000000e-10, ...,\n",
       "        1.00000000e-10, 1.00000000e-10, 1.00000000e-10],\n",
       "       [1.81818182e-02, 1.00000000e-10, 1.00000000e-10, ...,\n",
       "        1.00000000e-10, 1.00000000e-10, 1.00000000e-10],\n",
       "       [1.00000000e-10, 1.00000000e-10, 1.00000000e-10, ...,\n",
       "        1.00000000e-10, 1.00000000e-10, 1.00000000e-10]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(emmission_matrix)\n",
    "# np.array(transition_matrix)\n",
    "# all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eed24bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transition and emission parameters in the HMM model:  2070 , 1043235\n"
     ]
    }
   ],
   "source": [
    "# Code for conversion of transition and emmission matrix to respective dictionary\n",
    "\n",
    "def calculate_trans_prob():\n",
    "    trans_prob_dict = {}\n",
    "    for i in range(len(transition_matrix)):\n",
    "        for j in range(len(transition_matrix[0])):\n",
    "            tag_at_i = all_tags[i]\n",
    "            tag_at_j = all_tags[j]\n",
    "            trans_prob_dict['(' + tag_at_i + ', ' + tag_at_j + ')'] = transition_matrix[i][j]\n",
    "    return trans_prob_dict\n",
    "            \n",
    "def calculate_emmission_prob():\n",
    "    emmission_prob_dict = {}\n",
    "    for i in range(len(emmission_matrix)):\n",
    "        for j in range(len(vocabulary)):\n",
    "            tag_at_i = all_tags[i]\n",
    "            vocab_at_j = vocabulary[j]\n",
    "            emmission_prob_dict['(' + tag_at_i + ', ' + vocab_at_j + ')'] = emmission_matrix[i][j]\n",
    "    \n",
    "    return emmission_prob_dict\n",
    "\n",
    "start_tags = {} # maintains the initial tag frequency of all tag.\n",
    "def starting_transition_prob():\n",
    "    \n",
    "    start_tags_total = 0\n",
    "    start_tags_prob = {}\n",
    "    \n",
    "    for i in range(len(all_tags)):\n",
    "        start_tags[all_tags[i]]=0\n",
    "        \n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i]['idx']==1:\n",
    "            start_tags_total+=1\n",
    "            start_tags[df.loc[i]['tag']]+=1\n",
    "    \n",
    "    for tag in start_tags:\n",
    "        start_tags_prob[tag] = start_tags[tag]/start_tags_total\n",
    "    \n",
    "    return start_tags_prob\n",
    "\n",
    "# Probability Matrices\n",
    "trans_prob_dict = calculate_trans_prob()\n",
    "emmission_prob_dict = calculate_emmission_prob()\n",
    "start_tags_prob = starting_transition_prob()\n",
    "\n",
    "total_transition_prob = {}\n",
    "# Add both transition probs in to the final transition dictionary\n",
    "for key in start_tags_prob:\n",
    "    total_transition_prob['(' + '<s>' + ', ' + key + ')'] = start_tags_prob[key]\n",
    "    \n",
    "for key in trans_prob_dict:\n",
    "    total_transition_prob[key] = trans_prob_dict[key]\n",
    "\n",
    "print(\"Total transition and emission parameters in the HMM model: \", len(total_transition_prob), ',', len(emmission_prob_dict))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e98630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the dictionaries to the json file\n",
    "with open('hmm.json', 'w') as f:\n",
    "    json.dump({\"transition\": total_transition_prob, \"emission\": emmission_prob_dict}, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c656030e",
   "metadata": {},
   "source": [
    "Greedy Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eb6a6cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9351048568891318, 123201, 131751)\n"
     ]
    }
   ],
   "source": [
    "df_dev = pd.read_csv('./data/dev', sep='\\t', names=['idx', 'name', 'tag'])\n",
    "df_dev['frequency'] = df_dev['name'].map(df_dev['name'].value_counts())\n",
    "\n",
    "\n",
    "all_sentences_dev = []\n",
    "temp_sentence_dev = []\n",
    "for i in range(len(df_dev)):\n",
    "    if df_dev.loc[i]['idx']==1 and i!=0:\n",
    "        all_sentences_dev.append(temp_sentence_dev)\n",
    "        temp_sentence_dev =[]\n",
    "    temp_sentence_dev.append((df_dev.loc[i]['name'], df_dev.loc[i]['tag']))\n",
    "    \n",
    "from_tag = None\n",
    "tag_sequence = []\n",
    "sentence_scores = [] # score for each tag to word score for each sentence\n",
    "\n",
    "for sentence in all_sentences_dev:\n",
    "    curr_sentence_scores = []\n",
    "    curr_sequence = []\n",
    "    for i in range(len(sentence)):\n",
    "        max_score = float('-inf') # initialize max score\n",
    "        for j in range(len(all_tags)):\n",
    "            curr_score = 1\n",
    "            if i==0:\n",
    "                curr_score *= start_tags_prob[all_tags[j]]\n",
    "            else:\n",
    "#                 if str('(' + from_tag + ', ' + all_tags[j] + ')') in trans_prob_dict: #optional\n",
    "                curr_score *= trans_prob_dict['(' + from_tag + ', ' + all_tags[j] + ')']\n",
    "            \n",
    "            if str('(' + all_tags[j] + ', ' + sentence[i][0] + ')') in emmission_prob_dict:\n",
    "                curr_score *= emmission_prob_dict['(' + all_tags[j] + ', ' + sentence[i][0] + ')']\n",
    "            else:\n",
    "                curr_score *= emmission_prob_dict['(' + all_tags[j] + ', ' + '<unk>' + ')']\n",
    "            \n",
    "            if curr_score>max_score:\n",
    "                max_score = curr_score\n",
    "                highest_score_tag = all_tags[j]\n",
    "        \n",
    "        from_tag = highest_score_tag\n",
    "        curr_sequence.append(highest_score_tag)\n",
    "        curr_sentence_scores.append(max_score)\n",
    "    sentence_scores.append(curr_sentence_scores)\n",
    "    tag_sequence.append(curr_sequence)\n",
    "\n",
    "def accuracy_finder():\n",
    "    frequency = 0\n",
    "    cur_tag_freq = 0\n",
    "    \n",
    "    for i in range(len(all_sentences_dev)):\n",
    "        for j in range(len(all_sentences_dev[i])):\n",
    "            if tag_sequence[i][j]==all_sentences_dev[i][j][1]:\n",
    "                cur_tag_freq+=1\n",
    "            frequency+=1\n",
    "#     print(cur_tag_freq, frequency)\n",
    "    return cur_tag_freq/frequency, cur_tag_freq, frequency\n",
    "\n",
    "print(accuracy_finder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f25a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
